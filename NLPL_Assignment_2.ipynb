{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ***Experiment 2 : Introduction to Text Data Pre-Processing (Stopwords, Stemming, Lemmatization)***\n",
        "<hr>\n",
        "\n",
        "**Name:** Aayusha Bhatia (22070122004), Ayan Jain (22070122040)  \n",
        "**Lab:** NLP Lab-1"
      ],
      "metadata": {
        "id": "rt-Dz5Leusmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Using ***NLTK***"
      ],
      "metadata": {
        "id": "HmTtCz9ypTjl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBqKTVDJgYDU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(r\"/content/NLP Dataset.csv\")"
      ],
      "metadata": {
        "id": "30EvLp3KhQRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "85iZg7vLhkxU",
        "outputId": "9298b2ba-4459-47b2-fc06-edfaa1df9b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                track_id                 artists  \\\n",
              "0           0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
              "1           1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
              "2           2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
              "3           3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
              "4           4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
              "\n",
              "                                          album_name  \\\n",
              "0                                             Comedy   \n",
              "1                                   Ghost (Acoustic)   \n",
              "2                                     To Begin Again   \n",
              "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
              "4                                            Hold On   \n",
              "\n",
              "                   track_name  popularity  duration_ms  explicit  \\\n",
              "0                      Comedy          73       230666     False   \n",
              "1            Ghost - Acoustic          55       149610     False   \n",
              "2              To Begin Again          57       210826     False   \n",
              "3  Can't Help Falling In Love          71       201933     False   \n",
              "4                     Hold On          82       198853     False   \n",
              "\n",
              "   danceability  energy  ...  loudness  mode  speechiness  acousticness  \\\n",
              "0         0.676  0.4610  ...    -6.746     0       0.1430        0.0322   \n",
              "1         0.420  0.1660  ...   -17.235     1       0.0763        0.9240   \n",
              "2         0.438  0.3590  ...    -9.734     1       0.0557        0.2100   \n",
              "3         0.266  0.0596  ...   -18.515     1       0.0363        0.9050   \n",
              "4         0.618  0.4430  ...    -9.681     1       0.0526        0.4690   \n",
              "\n",
              "   instrumentalness  liveness  valence    tempo  time_signature  track_genre  \n",
              "0          0.000001    0.3580    0.715   87.917               4     acoustic  \n",
              "1          0.000006    0.1010    0.267   77.489               4     acoustic  \n",
              "2          0.000000    0.1170    0.120   76.332               4     acoustic  \n",
              "3          0.000071    0.1320    0.143  181.740               3     acoustic  \n",
              "4          0.000000    0.0829    0.167  119.949               4     acoustic  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3acc3c0-94da-43f3-b34e-478a5099171d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>track_id</th>\n",
              "      <th>artists</th>\n",
              "      <th>album_name</th>\n",
              "      <th>track_name</th>\n",
              "      <th>popularity</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>explicit</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>...</th>\n",
              "      <th>loudness</th>\n",
              "      <th>mode</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>liveness</th>\n",
              "      <th>valence</th>\n",
              "      <th>tempo</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>track_genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
              "      <td>Gen Hoshino</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>73</td>\n",
              "      <td>230666</td>\n",
              "      <td>False</td>\n",
              "      <td>0.676</td>\n",
              "      <td>0.4610</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.746</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1430</td>\n",
              "      <td>0.0322</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.3580</td>\n",
              "      <td>0.715</td>\n",
              "      <td>87.917</td>\n",
              "      <td>4</td>\n",
              "      <td>acoustic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
              "      <td>Ben Woodward</td>\n",
              "      <td>Ghost (Acoustic)</td>\n",
              "      <td>Ghost - Acoustic</td>\n",
              "      <td>55</td>\n",
              "      <td>149610</td>\n",
              "      <td>False</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.1660</td>\n",
              "      <td>...</td>\n",
              "      <td>-17.235</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0763</td>\n",
              "      <td>0.9240</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.1010</td>\n",
              "      <td>0.267</td>\n",
              "      <td>77.489</td>\n",
              "      <td>4</td>\n",
              "      <td>acoustic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
              "      <td>Ingrid Michaelson;ZAYN</td>\n",
              "      <td>To Begin Again</td>\n",
              "      <td>To Begin Again</td>\n",
              "      <td>57</td>\n",
              "      <td>210826</td>\n",
              "      <td>False</td>\n",
              "      <td>0.438</td>\n",
              "      <td>0.3590</td>\n",
              "      <td>...</td>\n",
              "      <td>-9.734</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0557</td>\n",
              "      <td>0.2100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>0.120</td>\n",
              "      <td>76.332</td>\n",
              "      <td>4</td>\n",
              "      <td>acoustic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n",
              "      <td>Kina Grannis</td>\n",
              "      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>\n",
              "      <td>Can't Help Falling In Love</td>\n",
              "      <td>71</td>\n",
              "      <td>201933</td>\n",
              "      <td>False</td>\n",
              "      <td>0.266</td>\n",
              "      <td>0.0596</td>\n",
              "      <td>...</td>\n",
              "      <td>-18.515</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.9050</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>0.1320</td>\n",
              "      <td>0.143</td>\n",
              "      <td>181.740</td>\n",
              "      <td>3</td>\n",
              "      <td>acoustic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5vjLSffimiIP26QG5WcN2K</td>\n",
              "      <td>Chord Overstreet</td>\n",
              "      <td>Hold On</td>\n",
              "      <td>Hold On</td>\n",
              "      <td>82</td>\n",
              "      <td>198853</td>\n",
              "      <td>False</td>\n",
              "      <td>0.618</td>\n",
              "      <td>0.4430</td>\n",
              "      <td>...</td>\n",
              "      <td>-9.681</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0526</td>\n",
              "      <td>0.4690</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0829</td>\n",
              "      <td>0.167</td>\n",
              "      <td>119.949</td>\n",
              "      <td>4</td>\n",
              "      <td>acoustic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3acc3c0-94da-43f3-b34e-478a5099171d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d3acc3c0-94da-43f3-b34e-478a5099171d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d3acc3c0-94da-43f3-b34e-478a5099171d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-81cfab15-4fb1-4ec8-889e-638f1836c08d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81cfab15-4fb1-4ec8-889e-638f1836c08d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-81cfab15-4fb1-4ec8-889e-638f1836c08d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import spacy\n",
        "\n",
        "# NLTK Downloads\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')  # If you're using POS for lemmatization\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab') # Added download for punkt_tab\n",
        "\n",
        "# Load SpaCy model\n",
        "# nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glPiKQDXilbp",
        "outputId": "b766f86d-369f-4ec3-e9b1-4cb26c3a5f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    if pd.isnull(text):\n",
        "        return {\n",
        "            'lowercase': \"\",\n",
        "            'no_punctuation': \"\",\n",
        "            'tokens': [],\n",
        "            'no_stopwords': [],\n",
        "            'stemmed': [],\n",
        "            'lemmatized': []\n",
        "        }\n",
        "\n",
        "    # 1. Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # 2. Remove punctuation\n",
        "    text_nopunct = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "\n",
        "    # 3. Tokenization\n",
        "    tokens = word_tokenize(text_nopunct)\n",
        "\n",
        "    # 4. Stopword Removal\n",
        "    tokens_no_stop = [word for word in tokens if word not in STOPWORDS]\n",
        "\n",
        "    # 5. Stemming\n",
        "    stemmed = [stemmer.stem(word) for word in tokens_no_stop]\n",
        "\n",
        "    # 6. Lemmatization\n",
        "    doc = nlp(\" \".join(tokens_no_stop))\n",
        "    lemmatized = [token.lemma_ for token in doc]\n",
        "\n",
        "    return {\n",
        "        'lowercase': text,\n",
        "        'no_punctuation': text_nopunct,\n",
        "        'tokens': tokens,\n",
        "        'no_stopwords': tokens_no_stop,\n",
        "        'stemmed': stemmed,\n",
        "        'lemmatized': lemmatized\n",
        "    }"
      ],
      "metadata": {
        "id": "PWq5osn9i8Jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to a few rows to preview the output\n",
        "for index, row in df[['track_name']].head(10).iterrows():\n",
        "    print(f\"\\nðŸŽµ Original Track Name: {row['track_name']}\")\n",
        "    result = preprocess_text(row['track_name'])\n",
        "    print(\" - Lowercase:\", result['lowercase'])\n",
        "    print(\" - No Punctuation:\", result['no_punctuation'])\n",
        "    print(\" - Tokens:\", result['tokens'])\n",
        "    print(\" - No Stopwords:\", result['no_stopwords'])\n",
        "    print(\" - Stemmed:\", result['stemmed'])\n",
        "    print(\" - Lemmatized:\", result['lemmatized'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZpFXO5ijWpi",
        "outputId": "7551a317-26d4-44d5-df0b-b7d5ede3ef82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽµ Original Track Name: Comedy\n",
            " - Lowercase: comedy\n",
            " - No Punctuation: comedy\n",
            " - Tokens: ['comedy']\n",
            " - No Stopwords: ['comedy']\n",
            " - Stemmed: ['comedi']\n",
            " - Lemmatized: ['comedy']\n",
            "\n",
            "ðŸŽµ Original Track Name: Ghost - Acoustic\n",
            " - Lowercase: ghost - acoustic\n",
            " - No Punctuation: ghost  acoustic\n",
            " - Tokens: ['ghost', 'acoustic']\n",
            " - No Stopwords: ['ghost', 'acoustic']\n",
            " - Stemmed: ['ghost', 'acoust']\n",
            " - Lemmatized: ['ghost', 'acoustic']\n",
            "\n",
            "ðŸŽµ Original Track Name: To Begin Again\n",
            " - Lowercase: to begin again\n",
            " - No Punctuation: to begin again\n",
            " - Tokens: ['to', 'begin', 'again']\n",
            " - No Stopwords: ['begin']\n",
            " - Stemmed: ['begin']\n",
            " - Lemmatized: ['begin']\n",
            "\n",
            "ðŸŽµ Original Track Name: Can't Help Falling In Love\n",
            " - Lowercase: can't help falling in love\n",
            " - No Punctuation: cant help falling in love\n",
            " - Tokens: ['cant', 'help', 'falling', 'in', 'love']\n",
            " - No Stopwords: ['cant', 'help', 'falling', 'love']\n",
            " - Stemmed: ['cant', 'help', 'fall', 'love']\n",
            " - Lemmatized: ['can', 'not', 'help', 'fall', 'love']\n",
            "\n",
            "ðŸŽµ Original Track Name: Hold On\n",
            " - Lowercase: hold on\n",
            " - No Punctuation: hold on\n",
            " - Tokens: ['hold', 'on']\n",
            " - No Stopwords: ['hold']\n",
            " - Stemmed: ['hold']\n",
            " - Lemmatized: ['hold']\n",
            "\n",
            "ðŸŽµ Original Track Name: Days I Will Remember\n",
            " - Lowercase: days i will remember\n",
            " - No Punctuation: days i will remember\n",
            " - Tokens: ['days', 'i', 'will', 'remember']\n",
            " - No Stopwords: ['days', 'remember']\n",
            " - Stemmed: ['day', 'rememb']\n",
            " - Lemmatized: ['day', 'remember']\n",
            "\n",
            "ðŸŽµ Original Track Name: Say Something\n",
            " - Lowercase: say something\n",
            " - No Punctuation: say something\n",
            " - Tokens: ['say', 'something']\n",
            " - No Stopwords: ['say', 'something']\n",
            " - Stemmed: ['say', 'someth']\n",
            " - Lemmatized: ['say', 'something']\n",
            "\n",
            "ðŸŽµ Original Track Name: I'm Yours\n",
            " - Lowercase: i'm yours\n",
            " - No Punctuation: im yours\n",
            " - Tokens: ['im', 'yours']\n",
            " - No Stopwords: ['im']\n",
            " - Stemmed: ['im']\n",
            " - Lemmatized: ['I', 'm']\n",
            "\n",
            "ðŸŽµ Original Track Name: Lucky\n",
            " - Lowercase: lucky\n",
            " - No Punctuation: lucky\n",
            " - Tokens: ['lucky']\n",
            " - No Stopwords: ['lucky']\n",
            " - Stemmed: ['lucki']\n",
            " - Lemmatized: ['lucky']\n",
            "\n",
            "ðŸŽµ Original Track Name: Hunger\n",
            " - Lowercase: hunger\n",
            " - No Punctuation: hunger\n",
            " - Tokens: ['hunger']\n",
            " - No Stopwords: ['hunger']\n",
            " - Stemmed: ['hunger']\n",
            " - Lemmatized: ['hunger']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to a few rows to preview the output\n",
        "for index, row in df[['artists']].head(10).iterrows():\n",
        "    print(f\"\\nðŸŽµ Original Artists Name: {row['artists']}\")\n",
        "    result = preprocess_text(row['artists'])\n",
        "    print(\" - Lowercase:\", result['lowercase'])\n",
        "    print(\" - No Punctuation:\", result['no_punctuation'])\n",
        "    print(\" - Tokens:\", result['tokens'])\n",
        "    print(\" - No Stopwords:\", result['no_stopwords'])\n",
        "    print(\" - Stemmed:\", result['stemmed'])\n",
        "    print(\" - Lemmatized:\", result['lemmatized'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkcn3nsrkXi7",
        "outputId": "448908a6-b5f8-4de9-92fa-c6c44a119b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽµ Original Artists Name: Gen Hoshino\n",
            " - Lowercase: gen hoshino\n",
            " - No Punctuation: gen hoshino\n",
            " - Tokens: ['gen', 'hoshino']\n",
            " - No Stopwords: ['gen', 'hoshino']\n",
            " - Stemmed: ['gen', 'hoshino']\n",
            " - Lemmatized: ['gen', 'hoshino']\n",
            "\n",
            "ðŸŽµ Original Artists Name: Ben Woodward\n",
            " - Lowercase: ben woodward\n",
            " - No Punctuation: ben woodward\n",
            " - Tokens: ['ben', 'woodward']\n",
            " - No Stopwords: ['ben', 'woodward']\n",
            " - Stemmed: ['ben', 'woodward']\n",
            " - Lemmatized: ['ben', 'woodward']\n",
            "\n",
            "ðŸŽµ Original Artists Name: Ingrid Michaelson;ZAYN\n",
            " - Lowercase: ingrid michaelson;zayn\n",
            " - No Punctuation: ingrid michaelsonzayn\n",
            " - Tokens: ['ingrid', 'michaelsonzayn']\n",
            " - No Stopwords: ['ingrid', 'michaelsonzayn']\n",
            " - Stemmed: ['ingrid', 'michaelsonzayn']\n",
            " - Lemmatized: ['ingrid', 'michaelsonzayn']\n",
            "\n",
            "ðŸŽµ Original Artists Name: Kina Grannis\n",
            " - Lowercase: kina grannis\n",
            " - No Punctuation: kina grannis\n",
            " - Tokens: ['kina', 'grannis']\n",
            " - No Stopwords: ['kina', 'grannis']\n",
            " - Stemmed: ['kina', 'granni']\n",
            " - Lemmatized: ['kina', 'granni']\n",
            "\n",
            "ðŸŽµ Original Artists Name: Chord Overstreet\n",
            " - Lowercase: chord overstreet\n",
            " - No Punctuation: chord overstreet\n",
            " - Tokens: ['chord', 'overstreet']\n",
            " - No Stopwords: ['chord', 'overstreet']\n",
            " - Stemmed: ['chord', 'overstreet']\n",
            " - Lemmatized: ['chord', 'overstreet']\n",
            "\n",
            "ðŸŽµ Original Artists Name: Tyrone Wells\n",
            " - Lowercase: tyrone wells\n",
            " - No Punctuation: tyrone wells\n",
            " - Tokens: ['tyrone', 'wells']\n",
            " - No Stopwords: ['tyrone', 'wells']\n",
            " - Stemmed: ['tyron', 'well']\n",
            " - Lemmatized: ['tyrone', 'well']\n",
            "\n",
            "ðŸŽµ Original Artists Name: A Great Big World;Christina Aguilera\n",
            " - Lowercase: a great big world;christina aguilera\n",
            " - No Punctuation: a great big worldchristina aguilera\n",
            " - Tokens: ['a', 'great', 'big', 'worldchristina', 'aguilera']\n",
            " - No Stopwords: ['great', 'big', 'worldchristina', 'aguilera']\n",
            " - Stemmed: ['great', 'big', 'worldchristina', 'aguilera']\n",
            " - Lemmatized: ['great', 'big', 'worldchristina', 'aguilera']\n",
            "\n",
            "ðŸŽµ Original Artists Name: Jason Mraz\n",
            " - Lowercase: jason mraz\n",
            " - No Punctuation: jason mraz\n",
            " - Tokens: ['jason', 'mraz']\n",
            " - No Stopwords: ['jason', 'mraz']\n",
            " - Stemmed: ['jason', 'mraz']\n",
            " - Lemmatized: ['jason', 'mraz']\n",
            "\n",
            "ðŸŽµ Original Artists Name: Jason Mraz;Colbie Caillat\n",
            " - Lowercase: jason mraz;colbie caillat\n",
            " - No Punctuation: jason mrazcolbie caillat\n",
            " - Tokens: ['jason', 'mrazcolbie', 'caillat']\n",
            " - No Stopwords: ['jason', 'mrazcolbie', 'caillat']\n",
            " - Stemmed: ['jason', 'mrazcolbi', 'caillat']\n",
            " - Lemmatized: ['jason', 'mrazcolbie', 'caillat']\n",
            "\n",
            "ðŸŽµ Original Artists Name: Ross Copperman\n",
            " - Lowercase: ross copperman\n",
            " - No Punctuation: ross copperman\n",
            " - Tokens: ['ross', 'copperman']\n",
            " - No Stopwords: ['ross', 'copperman']\n",
            " - Stemmed: ['ross', 'copperman']\n",
            " - Lemmatized: ['ross', 'copperman']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to a few rows to preview the output\n",
        "for index, row in df[['album_name']].head(10).iterrows():\n",
        "    print(f\"\\nðŸŽµ Original Album Name: {row['album_name']}\")\n",
        "    result = preprocess_text(row['album_name'])\n",
        "    print(\" - Lowercase:\", result['lowercase'])\n",
        "    print(\" - No Punctuation:\", result['no_punctuation'])\n",
        "    print(\" - Tokens:\", result['tokens'])\n",
        "    print(\" - No Stopwords:\", result['no_stopwords'])\n",
        "    print(\" - Stemmed:\", result['stemmed'])\n",
        "    print(\" - Lemmatized:\", result['lemmatized'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxfR3NvSkudj",
        "outputId": "ef322cff-26ed-443a-ee84-bb34f22e34d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽµ Original Album Name: Comedy\n",
            " - Lowercase: comedy\n",
            " - No Punctuation: comedy\n",
            " - Tokens: ['comedy']\n",
            " - No Stopwords: ['comedy']\n",
            " - Stemmed: ['comedi']\n",
            " - Lemmatized: ['comedy']\n",
            "\n",
            "ðŸŽµ Original Album Name: Ghost (Acoustic)\n",
            " - Lowercase: ghost (acoustic)\n",
            " - No Punctuation: ghost acoustic\n",
            " - Tokens: ['ghost', 'acoustic']\n",
            " - No Stopwords: ['ghost', 'acoustic']\n",
            " - Stemmed: ['ghost', 'acoust']\n",
            " - Lemmatized: ['ghost', 'acoustic']\n",
            "\n",
            "ðŸŽµ Original Album Name: To Begin Again\n",
            " - Lowercase: to begin again\n",
            " - No Punctuation: to begin again\n",
            " - Tokens: ['to', 'begin', 'again']\n",
            " - No Stopwords: ['begin']\n",
            " - Stemmed: ['begin']\n",
            " - Lemmatized: ['begin']\n",
            "\n",
            "ðŸŽµ Original Album Name: Crazy Rich Asians (Original Motion Picture Soundtrack)\n",
            " - Lowercase: crazy rich asians (original motion picture soundtrack)\n",
            " - No Punctuation: crazy rich asians original motion picture soundtrack\n",
            " - Tokens: ['crazy', 'rich', 'asians', 'original', 'motion', 'picture', 'soundtrack']\n",
            " - No Stopwords: ['crazy', 'rich', 'asians', 'original', 'motion', 'picture', 'soundtrack']\n",
            " - Stemmed: ['crazi', 'rich', 'asian', 'origin', 'motion', 'pictur', 'soundtrack']\n",
            " - Lemmatized: ['crazy', 'rich', 'asians', 'original', 'motion', 'picture', 'soundtrack']\n",
            "\n",
            "ðŸŽµ Original Album Name: Hold On\n",
            " - Lowercase: hold on\n",
            " - No Punctuation: hold on\n",
            " - Tokens: ['hold', 'on']\n",
            " - No Stopwords: ['hold']\n",
            " - Stemmed: ['hold']\n",
            " - Lemmatized: ['hold']\n",
            "\n",
            "ðŸŽµ Original Album Name: Days I Will Remember\n",
            " - Lowercase: days i will remember\n",
            " - No Punctuation: days i will remember\n",
            " - Tokens: ['days', 'i', 'will', 'remember']\n",
            " - No Stopwords: ['days', 'remember']\n",
            " - Stemmed: ['day', 'rememb']\n",
            " - Lemmatized: ['day', 'remember']\n",
            "\n",
            "ðŸŽµ Original Album Name: Is There Anybody Out There?\n",
            " - Lowercase: is there anybody out there?\n",
            " - No Punctuation: is there anybody out there\n",
            " - Tokens: ['is', 'there', 'anybody', 'out', 'there']\n",
            " - No Stopwords: ['anybody']\n",
            " - Stemmed: ['anybodi']\n",
            " - Lemmatized: ['anybody']\n",
            "\n",
            "ðŸŽµ Original Album Name: We Sing. We Dance. We Steal Things.\n",
            " - Lowercase: we sing. we dance. we steal things.\n",
            " - No Punctuation: we sing we dance we steal things\n",
            " - Tokens: ['we', 'sing', 'we', 'dance', 'we', 'steal', 'things']\n",
            " - No Stopwords: ['sing', 'dance', 'steal', 'things']\n",
            " - Stemmed: ['sing', 'danc', 'steal', 'thing']\n",
            " - Lemmatized: ['sing', 'dance', 'steal', 'thing']\n",
            "\n",
            "ðŸŽµ Original Album Name: We Sing. We Dance. We Steal Things.\n",
            " - Lowercase: we sing. we dance. we steal things.\n",
            " - No Punctuation: we sing we dance we steal things\n",
            " - Tokens: ['we', 'sing', 'we', 'dance', 'we', 'steal', 'things']\n",
            " - No Stopwords: ['sing', 'dance', 'steal', 'things']\n",
            " - Stemmed: ['sing', 'danc', 'steal', 'thing']\n",
            " - Lemmatized: ['sing', 'dance', 'steal', 'thing']\n",
            "\n",
            "ðŸŽµ Original Album Name: Hunger\n",
            " - Lowercase: hunger\n",
            " - No Punctuation: hunger\n",
            " - Tokens: ['hunger']\n",
            " - No Stopwords: ['hunger']\n",
            " - Stemmed: ['hunger']\n",
            " - Lemmatized: ['hunger']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to a few rows to preview the output\n",
        "for index, row in df[['track_name', 'artists', 'album_name']].head(10).iterrows():\n",
        "    print(f\"\\nðŸŽµ Original Track Name: {row['track_name']}\")\n",
        "    result = preprocess_text(row['track_name'])\n",
        "    print(\" - Lowercase:\", result['lowercase'])\n",
        "    print(\" - No Punctuation:\", result['no_punctuation'])\n",
        "    print(\" - Tokens:\", result['tokens'])\n",
        "    print(\" - No Stopwords:\", result['no_stopwords'])\n",
        "    print(\" - Stemmed:\", result['stemmed'])\n",
        "    print(\" - Lemmatized:\", result['lemmatized'])\n",
        "\n",
        "    print(f\"\\nðŸŽµ Original Artist Name: {row['artists']}\")\n",
        "    result1= preprocess_text(row['artists'])\n",
        "    print(\" - Lowercase:\", result1['lowercase'])\n",
        "    print(\" - No Punctuation:\", result1['no_punctuation'])\n",
        "    print(\" - Tokens:\", result1['tokens'])\n",
        "    print(\" - No Stopwords:\", result1['no_stopwords'])\n",
        "    print(\" - Stemmed:\", result1['stemmed'])\n",
        "    print(\" - Lemmatized:\", result1['lemmatized'])\n",
        "\n",
        "\n",
        "    print(f\"\\nðŸŽµ Original Album Name: {row['album_name']}\")\n",
        "    result2 = preprocess_text(row['album_name'])\n",
        "    print(\" - Lowercase:\", result2['lowercase'])\n",
        "    print(\" - No Punctuation:\", result2['no_punctuation'])\n",
        "    print(\" - Tokens:\", result2['tokens'])\n",
        "    print(\" - No Stopwords:\", result2['no_stopwords'])\n",
        "    print(\" - Stemmed:\", result2['stemmed'])\n",
        "    print(\" - Lemmatized:\", result2['lemmatized'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RCxpI9Dl3Jo",
        "outputId": "6d56a348-a939-445f-81d9-50a7f6185e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽµ Original Track Name: Comedy\n",
            " - Lowercase: comedy\n",
            " - No Punctuation: comedy\n",
            " - Tokens: ['comedy']\n",
            " - No Stopwords: ['comedy']\n",
            " - Stemmed: ['comedi']\n",
            " - Lemmatized: ['comedy']\n",
            "\n",
            "ðŸŽµ Original Artist Name: Gen Hoshino\n",
            " - Lowercase: gen hoshino\n",
            " - No Punctuation: gen hoshino\n",
            " - Tokens: ['gen', 'hoshino']\n",
            " - No Stopwords: ['gen', 'hoshino']\n",
            " - Stemmed: ['gen', 'hoshino']\n",
            " - Lemmatized: ['gen', 'hoshino']\n",
            "\n",
            "ðŸŽµ Original Album Name: Comedy\n",
            " - Lowercase: comedy\n",
            " - No Punctuation: comedy\n",
            " - Tokens: ['comedy']\n",
            " - No Stopwords: ['comedy']\n",
            " - Stemmed: ['comedi']\n",
            " - Lemmatized: ['comedy']\n",
            "\n",
            "ðŸŽµ Original Track Name: Ghost - Acoustic\n",
            " - Lowercase: ghost - acoustic\n",
            " - No Punctuation: ghost  acoustic\n",
            " - Tokens: ['ghost', 'acoustic']\n",
            " - No Stopwords: ['ghost', 'acoustic']\n",
            " - Stemmed: ['ghost', 'acoust']\n",
            " - Lemmatized: ['ghost', 'acoustic']\n",
            "\n",
            "ðŸŽµ Original Artist Name: Ben Woodward\n",
            " - Lowercase: ben woodward\n",
            " - No Punctuation: ben woodward\n",
            " - Tokens: ['ben', 'woodward']\n",
            " - No Stopwords: ['ben', 'woodward']\n",
            " - Stemmed: ['ben', 'woodward']\n",
            " - Lemmatized: ['ben', 'woodward']\n",
            "\n",
            "ðŸŽµ Original Album Name: Ghost (Acoustic)\n",
            " - Lowercase: ghost (acoustic)\n",
            " - No Punctuation: ghost acoustic\n",
            " - Tokens: ['ghost', 'acoustic']\n",
            " - No Stopwords: ['ghost', 'acoustic']\n",
            " - Stemmed: ['ghost', 'acoust']\n",
            " - Lemmatized: ['ghost', 'acoustic']\n",
            "\n",
            "ðŸŽµ Original Track Name: To Begin Again\n",
            " - Lowercase: to begin again\n",
            " - No Punctuation: to begin again\n",
            " - Tokens: ['to', 'begin', 'again']\n",
            " - No Stopwords: ['begin']\n",
            " - Stemmed: ['begin']\n",
            " - Lemmatized: ['begin']\n",
            "\n",
            "ðŸŽµ Original Artist Name: Ingrid Michaelson;ZAYN\n",
            " - Lowercase: ingrid michaelson;zayn\n",
            " - No Punctuation: ingrid michaelsonzayn\n",
            " - Tokens: ['ingrid', 'michaelsonzayn']\n",
            " - No Stopwords: ['ingrid', 'michaelsonzayn']\n",
            " - Stemmed: ['ingrid', 'michaelsonzayn']\n",
            " - Lemmatized: ['ingrid', 'michaelsonzayn']\n",
            "\n",
            "ðŸŽµ Original Album Name: To Begin Again\n",
            " - Lowercase: to begin again\n",
            " - No Punctuation: to begin again\n",
            " - Tokens: ['to', 'begin', 'again']\n",
            " - No Stopwords: ['begin']\n",
            " - Stemmed: ['begin']\n",
            " - Lemmatized: ['begin']\n",
            "\n",
            "ðŸŽµ Original Track Name: Can't Help Falling In Love\n",
            " - Lowercase: can't help falling in love\n",
            " - No Punctuation: cant help falling in love\n",
            " - Tokens: ['cant', 'help', 'falling', 'in', 'love']\n",
            " - No Stopwords: ['cant', 'help', 'falling', 'love']\n",
            " - Stemmed: ['cant', 'help', 'fall', 'love']\n",
            " - Lemmatized: ['can', 'not', 'help', 'fall', 'love']\n",
            "\n",
            "ðŸŽµ Original Artist Name: Kina Grannis\n",
            " - Lowercase: kina grannis\n",
            " - No Punctuation: kina grannis\n",
            " - Tokens: ['kina', 'grannis']\n",
            " - No Stopwords: ['kina', 'grannis']\n",
            " - Stemmed: ['kina', 'granni']\n",
            " - Lemmatized: ['kina', 'granni']\n",
            "\n",
            "ðŸŽµ Original Album Name: Crazy Rich Asians (Original Motion Picture Soundtrack)\n",
            " - Lowercase: crazy rich asians (original motion picture soundtrack)\n",
            " - No Punctuation: crazy rich asians original motion picture soundtrack\n",
            " - Tokens: ['crazy', 'rich', 'asians', 'original', 'motion', 'picture', 'soundtrack']\n",
            " - No Stopwords: ['crazy', 'rich', 'asians', 'original', 'motion', 'picture', 'soundtrack']\n",
            " - Stemmed: ['crazi', 'rich', 'asian', 'origin', 'motion', 'pictur', 'soundtrack']\n",
            " - Lemmatized: ['crazy', 'rich', 'asians', 'original', 'motion', 'picture', 'soundtrack']\n",
            "\n",
            "ðŸŽµ Original Track Name: Hold On\n",
            " - Lowercase: hold on\n",
            " - No Punctuation: hold on\n",
            " - Tokens: ['hold', 'on']\n",
            " - No Stopwords: ['hold']\n",
            " - Stemmed: ['hold']\n",
            " - Lemmatized: ['hold']\n",
            "\n",
            "ðŸŽµ Original Artist Name: Chord Overstreet\n",
            " - Lowercase: chord overstreet\n",
            " - No Punctuation: chord overstreet\n",
            " - Tokens: ['chord', 'overstreet']\n",
            " - No Stopwords: ['chord', 'overstreet']\n",
            " - Stemmed: ['chord', 'overstreet']\n",
            " - Lemmatized: ['chord', 'overstreet']\n",
            "\n",
            "ðŸŽµ Original Album Name: Hold On\n",
            " - Lowercase: hold on\n",
            " - No Punctuation: hold on\n",
            " - Tokens: ['hold', 'on']\n",
            " - No Stopwords: ['hold']\n",
            " - Stemmed: ['hold']\n",
            " - Lemmatized: ['hold']\n",
            "\n",
            "ðŸŽµ Original Track Name: Days I Will Remember\n",
            " - Lowercase: days i will remember\n",
            " - No Punctuation: days i will remember\n",
            " - Tokens: ['days', 'i', 'will', 'remember']\n",
            " - No Stopwords: ['days', 'remember']\n",
            " - Stemmed: ['day', 'rememb']\n",
            " - Lemmatized: ['day', 'remember']\n",
            "\n",
            "ðŸŽµ Original Artist Name: Tyrone Wells\n",
            " - Lowercase: tyrone wells\n",
            " - No Punctuation: tyrone wells\n",
            " - Tokens: ['tyrone', 'wells']\n",
            " - No Stopwords: ['tyrone', 'wells']\n",
            " - Stemmed: ['tyron', 'well']\n",
            " - Lemmatized: ['tyrone', 'well']\n",
            "\n",
            "ðŸŽµ Original Album Name: Days I Will Remember\n",
            " - Lowercase: days i will remember\n",
            " - No Punctuation: days i will remember\n",
            " - Tokens: ['days', 'i', 'will', 'remember']\n",
            " - No Stopwords: ['days', 'remember']\n",
            " - Stemmed: ['day', 'rememb']\n",
            " - Lemmatized: ['day', 'remember']\n",
            "\n",
            "ðŸŽµ Original Track Name: Say Something\n",
            " - Lowercase: say something\n",
            " - No Punctuation: say something\n",
            " - Tokens: ['say', 'something']\n",
            " - No Stopwords: ['say', 'something']\n",
            " - Stemmed: ['say', 'someth']\n",
            " - Lemmatized: ['say', 'something']\n",
            "\n",
            "ðŸŽµ Original Artist Name: A Great Big World;Christina Aguilera\n",
            " - Lowercase: a great big world;christina aguilera\n",
            " - No Punctuation: a great big worldchristina aguilera\n",
            " - Tokens: ['a', 'great', 'big', 'worldchristina', 'aguilera']\n",
            " - No Stopwords: ['great', 'big', 'worldchristina', 'aguilera']\n",
            " - Stemmed: ['great', 'big', 'worldchristina', 'aguilera']\n",
            " - Lemmatized: ['great', 'big', 'worldchristina', 'aguilera']\n",
            "\n",
            "ðŸŽµ Original Album Name: Is There Anybody Out There?\n",
            " - Lowercase: is there anybody out there?\n",
            " - No Punctuation: is there anybody out there\n",
            " - Tokens: ['is', 'there', 'anybody', 'out', 'there']\n",
            " - No Stopwords: ['anybody']\n",
            " - Stemmed: ['anybodi']\n",
            " - Lemmatized: ['anybody']\n",
            "\n",
            "ðŸŽµ Original Track Name: I'm Yours\n",
            " - Lowercase: i'm yours\n",
            " - No Punctuation: im yours\n",
            " - Tokens: ['im', 'yours']\n",
            " - No Stopwords: ['im']\n",
            " - Stemmed: ['im']\n",
            " - Lemmatized: ['I', 'm']\n",
            "\n",
            "ðŸŽµ Original Artist Name: Jason Mraz\n",
            " - Lowercase: jason mraz\n",
            " - No Punctuation: jason mraz\n",
            " - Tokens: ['jason', 'mraz']\n",
            " - No Stopwords: ['jason', 'mraz']\n",
            " - Stemmed: ['jason', 'mraz']\n",
            " - Lemmatized: ['jason', 'mraz']\n",
            "\n",
            "ðŸŽµ Original Album Name: We Sing. We Dance. We Steal Things.\n",
            " - Lowercase: we sing. we dance. we steal things.\n",
            " - No Punctuation: we sing we dance we steal things\n",
            " - Tokens: ['we', 'sing', 'we', 'dance', 'we', 'steal', 'things']\n",
            " - No Stopwords: ['sing', 'dance', 'steal', 'things']\n",
            " - Stemmed: ['sing', 'danc', 'steal', 'thing']\n",
            " - Lemmatized: ['sing', 'dance', 'steal', 'thing']\n",
            "\n",
            "ðŸŽµ Original Track Name: Lucky\n",
            " - Lowercase: lucky\n",
            " - No Punctuation: lucky\n",
            " - Tokens: ['lucky']\n",
            " - No Stopwords: ['lucky']\n",
            " - Stemmed: ['lucki']\n",
            " - Lemmatized: ['lucky']\n",
            "\n",
            "ðŸŽµ Original Artist Name: Jason Mraz;Colbie Caillat\n",
            " - Lowercase: jason mraz;colbie caillat\n",
            " - No Punctuation: jason mrazcolbie caillat\n",
            " - Tokens: ['jason', 'mrazcolbie', 'caillat']\n",
            " - No Stopwords: ['jason', 'mrazcolbie', 'caillat']\n",
            " - Stemmed: ['jason', 'mrazcolbi', 'caillat']\n",
            " - Lemmatized: ['jason', 'mrazcolbie', 'caillat']\n",
            "\n",
            "ðŸŽµ Original Album Name: We Sing. We Dance. We Steal Things.\n",
            " - Lowercase: we sing. we dance. we steal things.\n",
            " - No Punctuation: we sing we dance we steal things\n",
            " - Tokens: ['we', 'sing', 'we', 'dance', 'we', 'steal', 'things']\n",
            " - No Stopwords: ['sing', 'dance', 'steal', 'things']\n",
            " - Stemmed: ['sing', 'danc', 'steal', 'thing']\n",
            " - Lemmatized: ['sing', 'dance', 'steal', 'thing']\n",
            "\n",
            "ðŸŽµ Original Track Name: Hunger\n",
            " - Lowercase: hunger\n",
            " - No Punctuation: hunger\n",
            " - Tokens: ['hunger']\n",
            " - No Stopwords: ['hunger']\n",
            " - Stemmed: ['hunger']\n",
            " - Lemmatized: ['hunger']\n",
            "\n",
            "ðŸŽµ Original Artist Name: Ross Copperman\n",
            " - Lowercase: ross copperman\n",
            " - No Punctuation: ross copperman\n",
            " - Tokens: ['ross', 'copperman']\n",
            " - No Stopwords: ['ross', 'copperman']\n",
            " - Stemmed: ['ross', 'copperman']\n",
            " - Lemmatized: ['ross', 'copperman']\n",
            "\n",
            "ðŸŽµ Original Album Name: Hunger\n",
            " - Lowercase: hunger\n",
            " - No Punctuation: hunger\n",
            " - Tokens: ['hunger']\n",
            " - No Stopwords: ['hunger']\n",
            " - Stemmed: ['hunger']\n",
            " - Lemmatized: ['hunger']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***Using SpacCy***"
      ],
      "metadata": {
        "id": "jWfK3tFzkimF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas nltk spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfr-XbiWiZoC",
        "outputId": "4c3cd11f-3425-49fb-a28c-9e37faf9ed1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.7.14)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m137.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHnMwTxvp1vm",
        "outputId": "edd7f400-bb6d-4a2c-9e79-b353d62409cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                track_id                 artists  \\\n",
            "0           0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
            "1           1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
            "2           2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
            "3           3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
            "4           4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
            "\n",
            "                                          album_name  \\\n",
            "0                                             Comedy   \n",
            "1                                   Ghost (Acoustic)   \n",
            "2                                     To Begin Again   \n",
            "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
            "4                                            Hold On   \n",
            "\n",
            "                   track_name  popularity  duration_ms  explicit  \\\n",
            "0                      Comedy          73       230666     False   \n",
            "1            Ghost - Acoustic          55       149610     False   \n",
            "2              To Begin Again          57       210826     False   \n",
            "3  Can't Help Falling In Love          71       201933     False   \n",
            "4                     Hold On          82       198853     False   \n",
            "\n",
            "   danceability  energy  ...  loudness  mode  speechiness  acousticness  \\\n",
            "0         0.676  0.4610  ...    -6.746     0       0.1430        0.0322   \n",
            "1         0.420  0.1660  ...   -17.235     1       0.0763        0.9240   \n",
            "2         0.438  0.3590  ...    -9.734     1       0.0557        0.2100   \n",
            "3         0.266  0.0596  ...   -18.515     1       0.0363        0.9050   \n",
            "4         0.618  0.4430  ...    -9.681     1       0.0526        0.4690   \n",
            "\n",
            "   instrumentalness  liveness  valence    tempo  time_signature  track_genre  \n",
            "0          0.000001    0.3580    0.715   87.917               4     acoustic  \n",
            "1          0.000006    0.1010    0.267   77.489               4     acoustic  \n",
            "2          0.000000    0.1170    0.120   76.332               4     acoustic  \n",
            "3          0.000071    0.1320    0.143  181.740               3     acoustic  \n",
            "4          0.000000    0.0829    0.167  119.949               4     acoustic  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load English pipeline\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "qS15achrqAZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/NLP Dataset.csv')\n",
        "# Use a smaller subset to speed up experimentation\n",
        "df = df.head(500)  #\n",
        "\n",
        "\n",
        "# Load SpaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Columns to apply NLP\n",
        "text_cols = ['artists', 'album_name', 'track_name', 'track_genre']\n",
        "\n",
        "# Function to process text using SpaCy\n",
        "def spacy_analyze(text):\n",
        "    doc = nlp(str(text))  # Convert to string in case of NaN\n",
        "    tokens = [token.text for token in doc]\n",
        "    pos = [token.pos_ for token in doc]\n",
        "    lemmas = [token.lemma_ for token in doc]\n",
        "    ents = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return pd.Series([tokens, pos, lemmas, ents])\n",
        "\n",
        "# Apply NLP to each column\n",
        "for col in text_cols:\n",
        "    print(f\"\\nProcessing column: {col}\")\n",
        "    df[[f'{col}_tokens', f'{col}_pos', f'{col}_lemmas', f'{col}_entities']] = df[col].apply(spacy_analyze)\n",
        "\n",
        "# Display sample result\n",
        "print(df[[col for col in df.columns if 'track_name' in col]].head())\n",
        "\n",
        "# Optional: Save all NLP results to a CSV\n",
        "df.to_csv('NLP_Processed_All_Text_Columns.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL3ZbWFtqEYz",
        "outputId": "ecc67cb5-bf21-4070-99a8-e04789724ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing column: artists\n",
            "\n",
            "Processing column: album_name\n",
            "\n",
            "Processing column: track_name\n",
            "\n",
            "Processing column: track_genre\n",
            "                   track_name                   track_name_tokens  \\\n",
            "0                      Comedy                            [Comedy]   \n",
            "1            Ghost - Acoustic                [Ghost, -, Acoustic]   \n",
            "2              To Begin Again                  [To, Begin, Again]   \n",
            "3  Can't Help Falling In Love  [Ca, n't, Help, Falling, In, Love]   \n",
            "4                     Hold On                          [Hold, On]   \n",
            "\n",
            "                       track_name_pos                 track_name_lemmas  \\\n",
            "0                              [NOUN]                          [comedy]   \n",
            "1                  [NOUN, PUNCT, ADJ]              [ghost, -, acoustic]   \n",
            "2                   [PART, VERB, ADV]                [to, begin, again]   \n",
            "3  [AUX, PART, VERB, VERB, ADP, NOUN]  [can, not, help, fall, in, love]   \n",
            "4                         [VERB, ADP]                        [hold, on]   \n",
            "\n",
            "         track_name_entities  \n",
            "0                         []  \n",
            "1  [(Ghost - Acoustic, ORG)]  \n",
            "2                         []  \n",
            "3      [(Love, WORK_OF_ART)]  \n",
            "4                         []  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Step 1: Import Libraries -----------------\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Enable progress_apply with tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "# ----------------- Step 2: Load Dataset -----------------\n",
        "df = pd.read_csv('/content/NLP Dataset.csv')  # Update path if needed\n",
        "\n",
        "# Optional: For testing, limit to 500 rows\n",
        "# df = df.head(500)\n",
        "\n",
        "# ----------------- Step 3: Load SpaCy Model -----------------\n",
        "# For faster but less accurate: use 'en_core_web_sm'\n",
        "# For better results (optional): use 'en_core_web_trf' if installed\n",
        "nlp = spacy.load(\"en_core_web_sm\")  # or en_core_web_trf\n",
        "\n",
        "# ----------------- Step 4: Combine Text Columns -----------------\n",
        "def combine_fields(row):\n",
        "    return (\n",
        "        f\"The track '{row['track_name']}' from the album '{row['album_name']}' \"\n",
        "        f\"by artist '{row['artists']}' belongs to the '{row['track_genre']}' genre.\"\n",
        "    )\n",
        "\n",
        "df['combined_text'] = df.apply(combine_fields, axis=1)\n",
        "\n",
        "# ----------------- Step 5: Define NLP Analysis Function -----------------\n",
        "def spacy_analyze(text):\n",
        "    doc = nlp(str(text))\n",
        "    tokens = [token.text for token in doc]\n",
        "    pos = [token.pos_ for token in doc]\n",
        "    lemmas = [token.lemma_ for token in doc]\n",
        "    ents = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return pd.Series([tokens, pos, lemmas, ents])\n",
        "\n",
        "# ----------------- Step 6: Apply NLP to Combined Text -----------------\n",
        "df[['tokens', 'pos_tags', 'lemmas', 'entities']] = df['combined_text'].progress_apply(spacy_analyze)\n",
        "\n",
        "# ----------------- Step 7: Preview and Save Output -----------------\n",
        "print(df[['combined_text', 'tokens', 'pos_tags', 'lemmas', 'entities']].head())\n",
        "\n",
        "# Optional: Save final result to CSV\n",
        "df.to_csv('NLP_Experiment1_SpaCy_Enhanced.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QWianJ2tqay",
        "outputId": "c1e65940-9c59-4fe0-f517-0b9ca17afe88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114000/114000 [13:49<00:00, 137.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       combined_text  \\\n",
            "0  The track 'Comedy' from the album 'Comedy' by ...   \n",
            "1  The track 'Ghost - Acoustic' from the album 'G...   \n",
            "2  The track 'To Begin Again' from the album 'To ...   \n",
            "3  The track 'Can't Help Falling In Love' from th...   \n",
            "4  The track 'Hold On' from the album 'Hold On' b...   \n",
            "\n",
            "                                              tokens  \\\n",
            "0  [The, track, ', Comedy, ', from, the, album, '...   \n",
            "1  [The, track, ', Ghost, -, Acoustic, ', from, t...   \n",
            "2  [The, track, ', To, Begin, Again, ', from, the...   \n",
            "3  [The, track, ', Ca, n't, Help, Falling, In, Lo...   \n",
            "4  [The, track, ', Hold, On, ', from, the, album,...   \n",
            "\n",
            "                                            pos_tags  \\\n",
            "0  [DET, NOUN, PUNCT, PROPN, PUNCT, ADP, DET, NOU...   \n",
            "1  [DET, NOUN, PUNCT, NOUN, PUNCT, PROPN, PUNCT, ...   \n",
            "2  [DET, NOUN, PUNCT, PART, VERB, ADV, PUNCT, ADP...   \n",
            "3  [DET, NOUN, PUNCT, AUX, PART, VERB, VERB, ADP,...   \n",
            "4  [DET, NOUN, PUNCT, VERB, ADP, PUNCT, ADP, DET,...   \n",
            "\n",
            "                                              lemmas  \\\n",
            "0  [the, track, ', Comedy, ', from, the, album, '...   \n",
            "1  [the, track, ', ghost, -, Acoustic, ', from, t...   \n",
            "2  [the, track, ', to, begin, again, ', from, the...   \n",
            "3  [the, track, ', can, not, help, fall, in, love...   \n",
            "4  [the, track, ', hold, on, ', from, the, album,...   \n",
            "\n",
            "                                            entities  \n",
            "0  [(Comedy, PERSON), (Comedy, PERSON), (Gen Hosh...  \n",
            "1  [(Ghost - Acoustic', WORK_OF_ART), (Ben Woodwa...  \n",
            "2                   [(Ingrid Michaelson;ZAYN', ORG)]  \n",
            "3  [(Love, WORK_OF_ART), (Crazy Rich Asians, PERS...  \n",
            "4  [('Hold On', WORK_OF_ART), ('Hold On', WORK_OF...  \n"
          ]
        }
      ]
    }
  ]
}